{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d93d838d754342c78ebe805042f57a4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b6e78f8a00e498ab146e09e0df2f4cc",
              "IPY_MODEL_67e52c88ddd5442c90788db185461248",
              "IPY_MODEL_23a80f0e73434602a9071030d4e6644f"
            ],
            "layout": "IPY_MODEL_76b0085a70844c3eaf0d5417cc2716b1"
          }
        },
        "6b6e78f8a00e498ab146e09e0df2f4cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0becf2f1e514974b8ac992d7e6a29d6",
            "placeholder": "​",
            "style": "IPY_MODEL_8113108c3d19464da8c4ed9fa743338b",
            "value": "Map: 100%"
          }
        },
        "67e52c88ddd5442c90788db185461248": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d7dfaf70c3c4b72a6730d9e71b8d62d",
            "max": 900,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1af8ab98a3684cb491c558c935877cb9",
            "value": 900
          }
        },
        "23a80f0e73434602a9071030d4e6644f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ff4f8b7220d4a86a4a0f0ff1c0db74f",
            "placeholder": "​",
            "style": "IPY_MODEL_dccf7fe5d61f40fe83d76920199029d8",
            "value": " 900/900 [00:00&lt;00:00, 1756.98 examples/s]"
          }
        },
        "76b0085a70844c3eaf0d5417cc2716b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0becf2f1e514974b8ac992d7e6a29d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8113108c3d19464da8c4ed9fa743338b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d7dfaf70c3c4b72a6730d9e71b8d62d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1af8ab98a3684cb491c558c935877cb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2ff4f8b7220d4a86a4a0f0ff1c0db74f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dccf7fe5d61f40fe83d76920199029d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ce1075766ae4ce6a7c7e0bc00d811be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_263955c2540d467282b97b210108a9f9",
              "IPY_MODEL_264d32fed5bc43f5a375d0fa75118929",
              "IPY_MODEL_e6c44a85e6bc4fc8927a82a3b241f8ea"
            ],
            "layout": "IPY_MODEL_a3ba564bc04c4715bfbbb8eea7a30208"
          }
        },
        "263955c2540d467282b97b210108a9f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ca60ae8481644e8a339baca82d4378d",
            "placeholder": "​",
            "style": "IPY_MODEL_c6f4f320dd6c42a4b0c8ba342483b40e",
            "value": "Map: 100%"
          }
        },
        "264d32fed5bc43f5a375d0fa75118929": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b366bc77d64d4f19bc0197d04f34bb59",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_63bea3fa618e424994b4d6bd632158f5",
            "value": 100
          }
        },
        "e6c44a85e6bc4fc8927a82a3b241f8ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cf5f5ea67224f57b025fe8f0cacfc88",
            "placeholder": "​",
            "style": "IPY_MODEL_f1328deac7244269b3f91762cc130ab3",
            "value": " 100/100 [00:00&lt;00:00, 511.32 examples/s]"
          }
        },
        "a3ba564bc04c4715bfbbb8eea7a30208": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ca60ae8481644e8a339baca82d4378d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6f4f320dd6c42a4b0c8ba342483b40e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b366bc77d64d4f19bc0197d04f34bb59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63bea3fa618e424994b4d6bd632158f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5cf5f5ea67224f57b025fe8f0cacfc88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1328deac7244269b3f91762cc130ab3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Install dependencies\n",
        "!pip install --quiet \\\n",
        "    tensorflow \\\n",
        "    sentence-transformers \\\n",
        "    transformers \\\n",
        "    torch \\\n",
        "    scikit-learn \\\n",
        "    datasets\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzYtsu0ymAs0",
        "outputId": "a2202b0a-4380-4782-f861-0a7a68fd5992"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Imports & Configuration\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    pipeline\n",
        ")\n",
        "from datasets import Dataset\n"
      ],
      "metadata": {
        "id": "G9ez-ajnmAv2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: VAE Custom Layers & Builder\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "def sampling(args):\n",
        "    mean, log_var = args\n",
        "    log_var = tf.clip_by_value(log_var, -5.0, 5.0)\n",
        "    eps = K.random_normal((K.shape(mean)[0], tf.shape(mean)[1]))\n",
        "    return mean + K.exp(0.5 * log_var) * eps\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable(package=\"Custom\")\n",
        "class VAELossLayer(tf.keras.layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        orig, recon, mean, log_var = inputs\n",
        "        recon_loss = tf.reduce_sum(tf.square(orig - recon), axis=1)\n",
        "        kl_loss    = -0.5 * tf.reduce_sum(1 + log_var - tf.square(mean) - tf.exp(log_var), axis=1)\n",
        "        self.add_loss(tf.reduce_mean(recon_loss + kl_loss))\n",
        "        return recon\n",
        "\n",
        "def build_vae(input_dim):\n",
        "    inp = tf.keras.Input(shape=(input_dim,))\n",
        "    x = tf.keras.layers.Dense(64, activation=\"relu\")(inp)\n",
        "    x = tf.keras.layers.Dense(32, activation=\"relu\")(x)\n",
        "    z_mean   = tf.keras.layers.Dense(4, name=\"z_mean\")(x)\n",
        "    z_logvar = tf.keras.layers.Dense(4, name=\"z_log_var\")(x)\n",
        "    z        = tf.keras.layers.Lambda(sampling, name=\"z\")([z_mean, z_logvar])\n",
        "\n",
        "    latent = tf.keras.Input(shape=(4,))\n",
        "    dx = tf.keras.layers.Dense(32, activation=\"relu\")(latent)\n",
        "    dx = tf.keras.layers.Dense(64, activation=\"relu\")(dx)\n",
        "    out = tf.keras.layers.Dense(input_dim, activation=\"linear\")(dx)\n",
        "    decoder = tf.keras.Model(latent, out, name=\"decoder\")\n",
        "\n",
        "    recon = decoder(z)\n",
        "    loss_layer = VAELossLayer()([inp, recon, z_mean, z_logvar])\n",
        "    vae = tf.keras.Model(inp, loss_layer, name=\"vae\")\n",
        "    vae.compile(optimizer=tf.keras.optimizers.Adam(1e-3))\n",
        "    return vae\n",
        "\n",
        "def load_vae(path, dim):\n",
        "    try:\n",
        "        m = tf.keras.models.load_model(\n",
        "            path,\n",
        "            custom_objects={\"sampling\": sampling, \"VAELossLayer\": VAELossLayer}\n",
        "        )\n",
        "        if m.input_shape[1] != dim:\n",
        "            print(f\"⚠️ VAE expects {m.input_shape[1]} dims, got {dim}.\")\n",
        "            return None\n",
        "        print(\"✅ Loaded VAE from disk\")\n",
        "        return m\n",
        "    except Exception:\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "lTEuTm_lmAy0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Data Loading & Preprocessing\n",
        "\n",
        "df = pd.read_csv(\"sampled_data1.csv\", low_memory=False)\n",
        "\n",
        "# Numeric features & label\n",
        "features = ['ts','PID','MINFLT','MAJFLT','VSTEXT','VSIZE','RSIZE','VGROW','RGROW','MEM']\n",
        "df = df.dropna(subset=features+['type']).reset_index(drop=True)\n",
        "\n",
        "X_df = df[features].astype(float)\n",
        "y    = df['type'].astype(int).values\n",
        "\n",
        "# Scale\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X_df).astype(np.float32)\n",
        "\n",
        "print(\"Samples:\", X.shape[0], \"Features:\", X.shape[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfbsP4Y5mA1w",
        "outputId": "959c20a1-6635-4ec7-c3e0-dd27a7a4e26a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples: 1000 Features: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Train or Load VAE on Normal Data Only\n",
        "\n",
        "normal_mask = (y == 0)\n",
        "X_norm = X[normal_mask]\n",
        "\n",
        "vae = load_vae(\"vae_model.keras\", X.shape[1])\n",
        "if vae is None:\n",
        "    vae = build_vae(X.shape[1])\n",
        "    vae.fit(\n",
        "        X_norm, X_norm,\n",
        "        epochs=20, batch_size=32, validation_split=0.1,\n",
        "        callbacks=[\n",
        "            tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True),\n",
        "            tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2)\n",
        "        ], verbose=1\n",
        "    )\n",
        "    vae.save(\"vae_model.keras\")\n",
        "    print(\"✅ Trained & saved VAE\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dK2UyNDmA4l",
        "outputId": "f5b5372e-b8b8-4805-f41e-d54e896e2de8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 12.2970 - val_loss: 13.7021 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.2918 - val_loss: 13.4203 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.8779 - val_loss: 13.6549 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.9459 - val_loss: 13.3984 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.6422 - val_loss: 13.3477 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.2262 - val_loss: 12.6812 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.4330 - val_loss: 12.6245 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 11.6578 - val_loss: 12.3294 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.6082 - val_loss: 11.6430 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 10.1402 - val_loss: 11.8436 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8.4472 - val_loss: 11.2300 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.4497 - val_loss: 11.2483 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 6.9466 - val_loss: 10.7520 - learning_rate: 0.0010\n",
            "Epoch 14/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.9663 - val_loss: 10.4521 - learning_rate: 0.0010\n",
            "Epoch 15/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7007 - val_loss: 10.4802 - learning_rate: 0.0010\n",
            "Epoch 16/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.4835 - val_loss: 10.4041 - learning_rate: 0.0010\n",
            "Epoch 17/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.5894 - val_loss: 9.8187 - learning_rate: 0.0010\n",
            "Epoch 18/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.6367 - val_loss: 9.6071 - learning_rate: 0.0010\n",
            "Epoch 19/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.3112 - val_loss: 9.6142 - learning_rate: 0.0010\n",
            "Epoch 20/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.2892 - val_loss: 9.5125 - learning_rate: 0.0010\n",
            "✅ Trained & saved VAE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: VAE Reconstruction & Flagging\n",
        "\n",
        "recon = vae.predict(X)\n",
        "errs  = np.mean((X - recon)**2, axis=1)\n",
        "\n",
        "thr = np.percentile(errs[normal_mask], 95)\n",
        "flags_vae = (errs > thr).astype(int)\n",
        "\n",
        "print(f\"Threshold={thr:.4f}, flagged {flags_vae.sum()} anomalies\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewXHIq7umA7s",
        "outputId": "a89626ef-a434-4ecb-84ce-a111cf11ac1f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Threshold=0.8334, flagged 53 anomalies\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Prepare Text Dataset for GPT-Neo\n",
        "\n",
        "def to_text(row):\n",
        "    mem = row['MEM'] * 100\n",
        "    return (f\"Time {int(row['ts'])}: PID {int(row['PID'])}, \"\n",
        "            f\"{int(row['MINFLT'])} minor faults, {int(row['MAJFLT'])} major faults, \"\n",
        "            f\"{mem:.1f}% memory.\")\n",
        "\n",
        "df['text'] = df.apply(to_text, axis=1)\n",
        "df['label_str'] = df['type'].map({0:\"Normal\", 1:\"Anomaly\"})\n",
        "\n",
        "# Hugging Face Dataset\n",
        "ds = Dataset.from_pandas(df[['text','label_str']])\n",
        "split = ds.train_test_split(test_size=0.1, seed=42)\n",
        "train_ds, eval_ds = split['train'], split['test']\n"
      ],
      "metadata": {
        "id": "t-iwBoximLQR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: Tokenize & Data Collator (with pad_token fix)\n",
        "\n",
        "model_name = \"EleutherAI/gpt-neo-125M\"\n",
        "tokenizer  = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Fix missing pad_token\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "def preprocess(ex):\n",
        "    entries = [\"Record: \" + t + \"\\nResult: \" + l for t,l in zip(ex['text'], ex['label_str'])]\n",
        "    return tokenizer(entries, truncation=True, padding=\"max_length\", max_length=128)\n",
        "\n",
        "train_tok = train_ds.map(preprocess, batched=True)\n",
        "eval_tok  = eval_ds.map(preprocess, batched=True)\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "d93d838d754342c78ebe805042f57a4c",
            "6b6e78f8a00e498ab146e09e0df2f4cc",
            "67e52c88ddd5442c90788db185461248",
            "23a80f0e73434602a9071030d4e6644f",
            "76b0085a70844c3eaf0d5417cc2716b1",
            "b0becf2f1e514974b8ac992d7e6a29d6",
            "8113108c3d19464da8c4ed9fa743338b",
            "1d7dfaf70c3c4b72a6730d9e71b8d62d",
            "1af8ab98a3684cb491c558c935877cb9",
            "2ff4f8b7220d4a86a4a0f0ff1c0db74f",
            "dccf7fe5d61f40fe83d76920199029d8",
            "6ce1075766ae4ce6a7c7e0bc00d811be",
            "263955c2540d467282b97b210108a9f9",
            "264d32fed5bc43f5a375d0fa75118929",
            "e6c44a85e6bc4fc8927a82a3b241f8ea",
            "a3ba564bc04c4715bfbbb8eea7a30208",
            "3ca60ae8481644e8a339baca82d4378d",
            "c6f4f320dd6c42a4b0c8ba342483b40e",
            "b366bc77d64d4f19bc0197d04f34bb59",
            "63bea3fa618e424994b4d6bd632158f5",
            "5cf5f5ea67224f57b025fe8f0cacfc88",
            "f1328deac7244269b3f91762cc130ab3"
          ]
        },
        "id": "CabjyjycmMTd",
        "outputId": "1f5e7598-2250-493e-922b-63240d4f8c5a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/900 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d93d838d754342c78ebe805042f57a4c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ce1075766ae4ce6a7c7e0bc00d811be"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: Fine-Tune GPT-Neo (fixed TrainingArguments)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "# Resize embeddings if we added a pad_token\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"gpt_neo_finetuned\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    logging_steps=100,\n",
        "    save_steps=500,\n",
        "    save_total_limit=2\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_tok,\n",
        "    eval_dataset=eval_tok,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.save_model(\"gpt_neo_finetuned\")\n",
        "tokenizer.save_pretrained(\"gpt_neo_finetuned\")\n",
        "print(\"✅ Saved fine-tuned GPT-Neo\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "Q9l_EcdhmNT7",
        "outputId": "2599462c-1405-467d-c140-a35955070be8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33marafatcoc01\u001b[0m (\u001b[33marafatcoc01-rmit-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250513_171407-as9kzd16</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/arafatcoc01-rmit-university/huggingface/runs/as9kzd16' target=\"_blank\">gpt_neo_finetuned</a></strong> to <a href='https://wandb.ai/arafatcoc01-rmit-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/arafatcoc01-rmit-university/huggingface' target=\"_blank\">https://wandb.ai/arafatcoc01-rmit-university/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/arafatcoc01-rmit-university/huggingface/runs/as9kzd16' target=\"_blank\">https://wandb.ai/arafatcoc01-rmit-university/huggingface/runs/as9kzd16</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [675/675 2:05:28, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.156000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.842700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.786700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.765100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.733800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.707500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved fine-tuned GPT-Neo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10: Inference via Few‐Shot Generative GPT-Neo with 4 Examples & Robust Parsing\n",
        "\n",
        "import torch\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# ── Reload fine-tuned GPT-Neo ─────────────────────────────────────────────────\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt_neo_finetuned\")\n",
        "model     = AutoModelForCausalLM.from_pretrained(\"gpt_neo_finetuned\")\n",
        "device    = 0 if torch.cuda.is_available() else -1\n",
        "\n",
        "gen = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "# ── Prepare 4 few-shot examples (2 normal, 2 anomaly) ──────────────────────────\n",
        "norm_examples = df[df['type'] == 0].sample(2, random_state=1)\n",
        "anom_examples = df[df['type'] == 1].sample(2, random_state=1)\n",
        "\n",
        "examples = []\n",
        "for _, row in norm_examples.iterrows():\n",
        "    examples.append((\"Normal\", to_text(row)))\n",
        "for _, row in anom_examples.iterrows():\n",
        "    examples.append((\"Anomaly\", to_text(row)))\n",
        "\n",
        "# ── Classify each VAE-flagged candidate ────────────────────────────────────────\n",
        "preds = []\n",
        "debug_raw = []\n",
        "\n",
        "candidate_idxs = np.where(flags_vae == 1)[0]\n",
        "for idx_i, i in enumerate(candidate_idxs):\n",
        "    cand_text = df.loc[i, 'text']\n",
        "\n",
        "    # Build prompt with 4 examples\n",
        "    prompt = \"\"\n",
        "    for j, (lbl, txt) in enumerate(examples, start=1):\n",
        "        prompt += f\"Example {j}:\\nRecord: {txt}\\nResult: {lbl}\\n\\n\"\n",
        "    prompt += f\"Now classify this record:\\nRecord: {cand_text}\\nResult:\"\n",
        "\n",
        "    # Generate\n",
        "    out = gen(prompt, max_new_tokens=5, truncation=True)[0]['generated_text']\n",
        "    if idx_i < 5:\n",
        "        debug_raw.append(out)\n",
        "\n",
        "    # Extract only the part after the last \"Result:\"\n",
        "    answer_section = out.split(\"Result:\")[-1].strip()\n",
        "\n",
        "    # Parse robustly\n",
        "    low = answer_section.lower()\n",
        "    if low.startswith(\"anomaly\"):\n",
        "        label = \"Anomaly\"\n",
        "    elif low.startswith(\"normal\"):\n",
        "        label = \"Normal\"\n",
        "    else:\n",
        "        # fallback: look for keywords anywhere\n",
        "        if \"anomaly\" in low:\n",
        "            label = \"Anomaly\"\n",
        "        elif \"normal\" in low:\n",
        "            label = \"Normal\"\n",
        "        else:\n",
        "            label = \"Unknown\"\n",
        "\n",
        "    preds.append((i, label))\n",
        "\n",
        "# ── Debug: print the first few raw generations ─────────────────────────────────\n",
        "print(\"Raw generations for first 5 candidates:\")\n",
        "for j, raw in enumerate(debug_raw, start=1):\n",
        "    print(f\"{j}:\", raw, \"\\n\")\n",
        "\n",
        "# ── Evaluate ───────────────────────────────────────────────────────────────────\n",
        "y_true = y[flags_vae == 1]\n",
        "y_pred = np.array([1 if lab == \"Anomaly\" else 0 for _, lab in preds])\n",
        "\n",
        "print(\"Subset accuracy:\", accuracy_score(y_true, y_pred))\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
        "print(\"Classification report:\\n\", classification_report(y_true, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCZEmBt-mOTE",
        "outputId": "d27e9fe9-827f-43b1-863d-d7dfd1f29bc4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw generations for first 5 candidates:\n",
            "1: Example 1:\n",
            "Record: Time 1556109955: PID 2774, 268 minor faults, 0 major faults, 2.0% memory.\n",
            "Result: Normal\n",
            "\n",
            "Example 2:\n",
            "Record: Time 1554338670: PID 3257, 14932 minor faults, 8 major faults, 7.0% memory.\n",
            "Result: Normal\n",
            "\n",
            "Example 3:\n",
            "Record: Time 1556216673: PID 3292, 1913 minor faults, 0 major faults, 0.0% memory.\n",
            "Result: Anomaly\n",
            "\n",
            "Example 4:\n",
            "Record: Time 1556523080: PID 2801, 8 minor faults, 0 major faults, 1.0% memory.\n",
            "Result: Anomaly\n",
            "\n",
            "Now classify this record:\n",
            "Record: Time 1556723370: PID 2533, 9 minor faults, 0 major faults, 7.0% memory.\n",
            "Result: Normal\n",
            "\n",
            "Result: \n",
            "\n",
            "2: Example 1:\n",
            "Record: Time 1556109955: PID 2774, 268 minor faults, 0 major faults, 2.0% memory.\n",
            "Result: Normal\n",
            "\n",
            "Example 2:\n",
            "Record: Time 1554338670: PID 3257, 14932 minor faults, 8 major faults, 7.0% memory.\n",
            "Result: Normal\n",
            "\n",
            "Example 3:\n",
            "Record: Time 1556216673: PID 3292, 1913 minor faults, 0 major faults, 0.0% memory.\n",
            "Result: Anomaly\n",
            "\n",
            "Example 4:\n",
            "Record: Time 1556523080: PID 2801, 8 minor faults, 0 major faults, 1.0% memory.\n",
            "Result: Anomaly\n",
            "\n",
            "Now classify this record:\n",
            "Record: Time 1556735150: PID 2533, 9 minor faults, 0 major faults, 7.0% memory.\n",
            "Result: Normal\n",
            "\n",
            "Result: \n",
            "\n",
            "3: Example 1:\n",
            "Record: Time 1556109955: PID 2774, 268 minor faults, 0 major faults, 2.0% memory.\n",
            "Result: Normal\n",
            "\n",
            "Example 2:\n",
            "Record: Time 1554338670: PID 3257, 14932 minor faults, 8 major faults, 7.0% memory.\n",
            "Result: Normal\n",
            "\n",
            "Example 3:\n",
            "Record: Time 1556216673: PID 3292, 1913 minor faults, 0 major faults, 0.0% memory.\n",
            "Result: Anomaly\n",
            "\n",
            "Example 4:\n",
            "Record: Time 1556523080: PID 2801, 8 minor faults, 0 major faults, 1.0% memory.\n",
            "Result: Anomaly\n",
            "\n",
            "Now classify this record:\n",
            "Record: Time 1557107640: PID 9073, 0 minor faults, 0 major faults, 0.0% memory.\n",
            "Result: Normal\n",
            "Result: Normal \n",
            "\n",
            "4: Example 1:\n",
            "Record: Time 1556109955: PID 2774, 268 minor faults, 0 major faults, 2.0% memory.\n",
            "Result: Normal\n",
            "\n",
            "Example 2:\n",
            "Record: Time 1554338670: PID 3257, 14932 minor faults, 8 major faults, 7.0% memory.\n",
            "Result: Normal\n",
            "\n",
            "Example 3:\n",
            "Record: Time 1556216673: PID 3292, 1913 minor faults, 0 major faults, 0.0% memory.\n",
            "Result: Anomaly\n",
            "\n",
            "Example 4:\n",
            "Record: Time 1556523080: PID 2801, 8 minor faults, 0 major faults, 1.0% memory.\n",
            "Result: Anomaly\n",
            "\n",
            "Now classify this record:\n",
            "Record: Time 1556812975: PID 8656, 0 minor faults, 0 major faults, 0.0% memory.\n",
            "Result: Normal\n",
            "\n",
            "Result: \n",
            "\n",
            "5: Example 1:\n",
            "Record: Time 1556109955: PID 2774, 268 minor faults, 0 major faults, 2.0% memory.\n",
            "Result: Normal\n",
            "\n",
            "Example 2:\n",
            "Record: Time 1554338670: PID 3257, 14932 minor faults, 8 major faults, 7.0% memory.\n",
            "Result: Normal\n",
            "\n",
            "Example 3:\n",
            "Record: Time 1556216673: PID 3292, 1913 minor faults, 0 major faults, 0.0% memory.\n",
            "Result: Anomaly\n",
            "\n",
            "Example 4:\n",
            "Record: Time 1556523080: PID 2801, 8 minor faults, 0 major faults, 1.0% memory.\n",
            "Result: Anomaly\n",
            "\n",
            "Now classify this record:\n",
            "Record: Time 1554229340: PID 3257, 10999 minor faults, 0 major faults, 5.0% memory.\n",
            "Result: Normal\n",
            "Result: Normal \n",
            "\n",
            "Subset accuracy: 0.8301886792452831\n",
            "Confusion matrix:\n",
            " [[44  0]\n",
            " [ 9  0]]\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      1.00      0.91        44\n",
            "           1       0.00      0.00      0.00         9\n",
            "\n",
            "    accuracy                           0.83        53\n",
            "   macro avg       0.42      0.50      0.45        53\n",
            "weighted avg       0.69      0.83      0.75        53\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10: Inference via Zero-Shot NLI Classification (3rd option)\n",
        "\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "# 1) Load zero-shot classifier\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "classifier = pipeline(\n",
        "    \"zero-shot-classification\",\n",
        "    model=\"facebook/bart-large-mnli\",\n",
        "    device=device\n",
        ")\n",
        "\n",
        "# 2) Candidate indices flagged by VAE\n",
        "candidates = np.where(flags_vae == 1)[0]\n",
        "\n",
        "# 3) Classify each with a hypothesis template\n",
        "candidate_labels = [\"normal\", \"anomaly\"]\n",
        "preds = []\n",
        "for i in candidates:\n",
        "    text = df.loc[i, 'text']\n",
        "    res = classifier(\n",
        "        text,\n",
        "        candidate_labels=candidate_labels,\n",
        "        hypothesis_template=\"This record is {}.\",\n",
        "        multi_label=False\n",
        "    )\n",
        "    top = res[\"labels\"][0].lower()\n",
        "    preds.append((i, top))\n",
        "\n",
        "# 4) Build y_pred and evaluate\n",
        "y_true = y[candidates]\n",
        "y_pred = np.array([1 if lab == \"anomaly\" else 0 for _, lab in preds])\n",
        "\n",
        "print(\"Subset accuracy:\", accuracy_score(y_true, y_pred))\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
        "print(\"Classification report:\\n\", classification_report(y_true, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVFvS7GwmPmZ",
        "outputId": "615bd595-68dd-4a69-d7cb-765bf40e758e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subset accuracy: 0.41509433962264153\n",
            "Confusion matrix:\n",
            " [[14 30]\n",
            " [ 1  8]]\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.32      0.47        44\n",
            "           1       0.21      0.89      0.34         9\n",
            "\n",
            "    accuracy                           0.42        53\n",
            "   macro avg       0.57      0.60      0.41        53\n",
            "weighted avg       0.81      0.42      0.45        53\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mapHXV8LQFy5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}